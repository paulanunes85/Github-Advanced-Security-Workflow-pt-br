<h1 align="center">GitHub Advanced Security: Protegiendo su Workflow</h1>
<h5 align="center">Revisi贸n para Espa帽ol @paulanunes85 - 2025</h5>

Si va a impartir esta sesi贸n, consulte la p谩gina de [recursos de entrega de sesi贸n](session-delivery-resources/README.es.md) para diapositivas, scripts de demostraci贸n y otros recursos.

## Descripci贸n de la Sesi贸n

Los recursos de GitHub Advanced Security est谩n integrados directamente en el flujo de trabajo de desarrollo, haci茅ndolos f谩ciles de usar y dando a los desarrolladores la capacidad de identificar posibles problemas de seguridad lo m谩s temprano posible en el ciclo de vida del desarrollo de software.

Aprenda c贸mo evitar que problemas de seguridad comunes se fusionen en su c贸digo, c贸mo encontrar y corregir vulnerabilidades m谩s r谩pidamente con IA y c贸mo mantener sus dependencias actualizadas a trav茅s de GitHub Advanced Security.

- Material [GitHub Advanced Security - Protegiendo su flujo de trabajo](https://github.com/paulanunes85/Github-Advanced-Security-Workflow-pt-br/blob/main/PT-BR_BRK422_Tech%20-%20GitHub%20Advanced%20Security%20-%20Paula%20Silva.pdf)

## Resultados de Aprendizaje

- Aprenda c贸mo habilitar alertas de Dependabot y recibir notificaciones sobre dependencias vulnerables, incluyendo un enlace al archivo afectado en el proyecto e informaci贸n sobre una versi贸n corregida.
- Vea c贸mo actualizar autom谩ticamente o generar una solicitud de extracci贸n para actualizar dependencias vulnerables.
- Descubra c贸mo actualizar autom谩ticamente paquetes soportados utilizados por su repositorio en una programaci贸n que usted configura.
- Aprenda c贸mo habilitar el escaneo de secretos y la protecci贸n de push que previene proactivamente filtraciones de secretos al escanear el c贸digo en el commit y bloquear un push si un secreto est谩 presente.
- Encuentre vulnerabilidades antes de que se fusionen al c贸digo con escaneos automatizados de CodeQL.
- Aprenda c贸mo obtener correcciones de c贸digo sugeridas por IA en solicitudes de extracci贸n.

## Tecnolog铆a Utilizada

        - GitHub Advanced Security
        - Dependabot
        - Escaneo de Secretos
        - CodeQL
        - Copilot Autofix
        - GitHub Actions

## Requisitos Previos

Antes de participar en el taller, hay solo un requisito previo: tener una cuenta p煤blica de GitHub. Todos los recursos, dependencias y datos ya forman parte del repositorio.
- **Requisitos previos:** Para usar GitHub Copilot, debe tener una suscripci贸n activa de GitHub Copilot Business o Enterprise. Inscr铆base para Copilot Free para VS Code solo para fines de entrenamiento [Copilot for free para VS Code](https://learn.microsoft.com/es-es/visualstudio/ide/copilot-free-plan?view=vs-2022).
- **Ya tener acceso o Habilitar GitHub Advanced Security:** [Habilitando GitHub Advanced Security](https://resources.github.com/es/learn/pathways/security/essentials/enabling-github-advanced-security/)
- **Tener acceso a una organizaci贸n GitHub con licencia de GitHub Advanced Security**

## Recursos Adicionales y Aprendizaje Continuo

| Recursos         | Enlaces                           | Descripci贸n        |
|:-----------------|:----------------------------------|:-------------------|
| Documentaci贸n    | [Documentaci贸n](https://docs.github.com/es/get-started/learning-about-github/about-github-advanced-security) | Sobre GitHub Advanced Security |
| Documentaci贸n    | [Documentaci贸n de actualizaciones de seguridad de Dependabot](https://docs.github.com/es/code-security/dependabot/dependabot-security-updates/about-dependabot-security-updates) | Sobre actualizaciones de seguridad de Dependabot |
| Documentaci贸n    | [Documentaci贸n de Copilot Autofix](https://docs.github.com/es/code-security/code-scanning/managing-code-scanning-alerts/about-autofix-for-codeql-code-scanning#autofix-generation-process) | Sobre Copilot Autofix para escaneo de c贸digo de CodeQL |
| Certificaci贸n    | [Programa de Certificaci贸n de GitHub Advanced Security](https://examregistration.github.com/) | Aprenda m谩s sobre las Certificaciones de GitHub |

## Propietarios del Contenido

<!-- ALL-CONTRIBUTORS-LIST:START - No elimine o modifique esta secci贸n -->

<table>
<tr>
         <td align="center"><a href="http://learnanalytics.microsoft.com">
                  <img src="https://developer.microsoft.com/en-us/advocates/media/profiles/joylynn-kirui.jpg" width="100px;" alt="Chris Testa-O'Neill
"/><br />
                  <sub><b>Joylynn Kirui
</b></sub></a><br />
                                <a href="[https://developer.microsoft.com/advocates/joylynn-kirui]" title="talk"></a> 
         </td>
</tr></table>

<!-- ALL-CONTRIBUTORS-LIST:END -->

## IA Responsable

Microsoft est谩 comprometida a ayudar a nuestros clientes a usar nuestros productos de IA de forma responsable, compartiendo nuestros aprendizajes y construyendo asociaciones basadas en la confianza a trav茅s de herramientas como Notas de Transparencia y Evaluaciones de Impacto. Muchos de estos recursos se pueden encontrar en https://aka.ms/RAI. El enfoque de Microsoft para IA responsable se basa en nuestros principios de IA de justicia, confiabilidad y seguridad, privacidad y seguridad, inclusi贸n, transparencia y responsabilidad.

Los modelos de lenguaje natural, imagen y habla a gran escala - como los utilizados en este ejemplo - pueden potencialmente comportarse de manera injusta, poco confiable u ofensiva, causando da帽os. Consulte la [nota de transparencia del servicio Azure OpenAI](https://learn.microsoft.com/es-es/legal/cognitive-services/openai/transparency-note?tabs=text) para informarse sobre riesgos y limitaciones.

El enfoque recomendado para mitigar estos riesgos es incluir un sistema de seguridad en su arquitectura que pueda detectar y prevenir comportamientos perjudiciales. [Azure AI Content Safety](https://learn.microsoft.com/es-es/azure/ai-services/content-safety/overview) proporciona una capa independiente de protecci贸n, capaz de detectar contenido da帽ino generado por usuarios e IA en aplicaciones y servicios. Azure AI Content Safety incluye APIs de texto e imagen que permiten detectar material da帽ino. Tambi茅n tenemos un Content Safety Studio interactivo que permite visualizar, explorar y probar c贸digos de ejemplo para detectar contenido da帽ino en diferentes modalidades. La siguiente [documentaci贸n de inicio r谩pido](https://learn.microsoft.com/es-es/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) lo gu铆a para hacer solicitudes al servicio.

Otro aspecto a considerar es el rendimiento general de la aplicaci贸n. Con aplicaciones multimodales y multimodelo, consideramos el rendimiento como el sistema funcionando conforme usted y sus usuarios esperan, incluyendo no generar salidas da帽inas. Es importante evaluar el rendimiento de su aplicaci贸n general utilizando [evaluadores de Rendimiento y Calidad y de Riesgo y Seguridad.](https://learn.microsoft.com/es-es/azure/ai-studio/concepts/evaluation-metrics-built-in?tabs=warning) Tambi茅n tiene la capacidad de crear y evaluar con [evaluadores personalizados.](https://learn.microsoft.com/es-es/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators)

Puede evaluar su aplicaci贸n de IA en su entorno de desarrollo utilizando el [SDK de Evaluaci贸n de Azure AI.](https://microsoft.github.io/promptflow/index.html) Dado un conjunto de datos de prueba o un objetivo, las generaciones de su aplicaci贸n de IA generativa se miden cuantitativamente con evaluadores integrados o evaluadores personalizados de su elecci贸n. Para empezar a usar el SDK de flujo de prompt para evaluar su sistema, puede seguir la [gu铆a de inicio r谩pido.](https://learn.microsoft.com/es-es/azure/ai-studio/how-to/develop/flow-evaluate-sdk) Despu茅s de ejecutar una evaluaci贸n, puede [visualizar los resultados en Azure AI Studio.](https://learn.microsoft.com/es-es/azure/ai-studio/how-to/evaluate-flow-results)

## Avisos Legales
 
Microsoft y cualquier colaborador le otorgan una licencia para la documentaci贸n de Microsoft y otros contenidos en este repositorio bajo la [Licencia P煤blica Internacional Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/legalcode),
vea [LICENSE](LICENSE) y le otorgan una licencia para cualquier c贸digo en el repositorio bajo la [Licencia MIT](https://opensource.org/licenses/MIT), consulte
[LICENSE-CODE](LICENSE-CODE)
 
Microsoft, Windows, Microsoft Azure y/u otros productos y servicios de Microsoft referenciados en la documentaci贸n pueden ser marcas comerciales o marcas registradas de Microsoft en los Estados Unidos y/u otros pa铆ses. Las licencias para este proyecto no le otorgan derechos para usar ning煤n nombre, logotipo o marca comercial de Microsoft. Las directrices generales de marcas comerciales de Microsoft se pueden encontrar en http://go.microsoft.com/fwlink/?LinkID=254653.
 
La informaci贸n de privacidad se puede encontrar en https://privacy.microsoft.com/es-es/
 
Microsoft y cualquier colaborador se reservan todos los dem谩s derechos, ya sea bajo sus respectivos derechos de autor, patentes o marcas comerciales, ya sea por implicaci贸n, impedimento legal o de otro modo. 