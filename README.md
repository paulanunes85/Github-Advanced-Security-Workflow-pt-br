
<h1 align="center">GitHub Advanced Security: Protegendo seu Workflow</h1>
<h5 align="center">Revis√£o para Portugu√™s Brasil @paulanunes85 - 2025</h5>

Se voc√™ for ministrar esta sess√£o, consulte a p√°gina de [recursos de entrega de sess√£o](https://github.com/microsoft/aitour-github-advanced-security-workflow/tree/main/session-delivery-resources#readme) para slides, scripts de demonstra√ß√£o e outros recursos.

## Descri√ß√£o da Sess√£o

Os recursos do GitHub Advanced Security s√£o integrados diretamente ao fluxo de trabalho de desenvolvimento, tornando-os f√°ceis de usar e dando aos desenvolvedores a capacidade de identificar poss√≠veis problemas de seguran√ßa o mais cedo poss√≠vel no ciclo de vida do desenvolvimento de software.

Aprenda como evitar que problemas de seguran√ßa comuns sejam mesclados ao seu c√≥digo, como encontrar e corrigir vulnerabilidades mais rapidamente com IA e como manter suas depend√™ncias atualizadas via GitHub Advanced Security.

- Material [GitHub Advanced Security - Protegendo seu fluxo de trabalho](https://github.com/paulanunes85/Github-Advanced-Security-Workflow-pt-br/blob/main/PT-BR_BRK422_Tech%20-%20GitHub%20Advanced%20Security%20-%20Paula%20Silva.pdf)

## Resultados de Aprendizagem

- Aprenda como habilitar alertas do Dependabot e receber notifica√ß√µes sobre depend√™ncias vulner√°veis, incluindo um link para o arquivo afetado no projeto e informa√ß√µes sobre uma vers√£o corrigida.
- Veja como atualizar automaticamente ou gerar uma solicita√ß√£o de pull para atualizar depend√™ncias vulner√°veis.
- Descubra como atualizar automaticamente pacotes suportados usados pelo seu reposit√≥rio em uma programa√ß√£o que voc√™ configura.
- Aprenda como habilitar a varredura de segredos e a prote√ß√£o de push que previne proativamente vazamentos de segredos ao escanear o c√≥digo no commit e bloquear um push se um segredo estiver presente.
- Encontre vulnerabilidades antes que elas sejam mescladas ao c√≥digo com varreduras automatizadas do CodeQL.
- Aprenda como obter corre√ß√µes de c√≥digo sugeridas por IA em solicita√ß√µes de pull.

## Tecnologia Utilizada

        - GitHub Advanced Security
        - Dependabot
        - Varredura de Segredos
        - CodeQL
        - Copilot Autofix
        - GitHub Actions

## Pr√©-requisitos

Antes de participar do workshop, h√° somente um pr√©-requisito: ter uma conta p√∫blica do GitHub. Todos os recursos, depend√™ncias e dados j√° fazem parte do reposit√≥rio.
- **Pr√©-requisitos:** Para usar o GitHub Copilot, voc√™ deve ter uma assinatura ativa do GitHub Copilot Business ou Enterprise. Inscreva-se para Copilot Free para VS Code apenas para fim de treinamento [Copilot for free para VS Code](https://learn.microsoft.com/en-us/visualstudio/ide/copilot-free-plan?view=vs-2022).
- **J√° possuir acesso ou Habilitar GitHub Advanced Security:** [Habilitando a seguran√ßa avan√ßada do GitHub](https://resources.github.com/pt-br/learn/pathways/security/essentials/enabling-github-advanced-security/)
- **Ter acesso a uma organiza√ß√£o GitHub com licen√ßa do GitHub Advanced Security**

## Recursos Adicionais e Aprendizado Cont√≠nuo

| Recursos          | Links                             | Descri√ß√£o        |
|:-------------------|:----------------------------------|:-------------------|
| Documenta√ß√£o  | [Documenta√ß√£o](https://docs.github.com/en/get-started/learning-about-github/about-github-advanced-security) | Sobre GitHub Advanced Security |
| Documenta√ß√£o  | [Documenta√ß√£o de atualiza√ß√µes de seguran√ßa do Dependabot](https://docs.github.com/en/code-security/dependabot/dependabot-security-updates/about-dependabot-security-updates) | Sobre atualiza√ß√µes de seguran√ßa do Dependabot |
| Documenta√ß√£o  | [Documenta√ß√£o do Copilot Autofix](https://docs.github.com/en/code-security/code-scanning/managing-code-scanning-alerts/about-autofix-for-codeql-code-scanning#autofix-generation-process) | Sobre o Copilot Autofix para varredura de c√≥digo do CodeQL |
| Certifica√ß√£o  | [Programa de Certifica√ß√£o do GitHub Advanced Security](https://examregistration.github.com/) | Saiba mais sobre as Certifica√ß√µes do GitHub |

## Propriet√°rios do Conte√∫do

<!-- ALL-CONTRIBUTORS-LIST:START - N√£o remova ou modifique esta se√ß√£o -->

<table>
<tr>
         <td align="center"><a href="http://learnanalytics.microsoft.com">
                  <img src="https://developer.microsoft.com/en-us/advocates/media/profiles/joylynn-kirui.jpg" width="100px;" alt="Chris Testa-O'Neill
"/><br />
                  <sub><b>Joylynn Kirui
</b></sub></a><br />
                                <a href="[https://developer.microsoft.com/advocates/joylynn-kirui]" title="talk">üì¢</a> 
         </td>
</tr></table>

<!-- ALL-CONTRIBUTORS-LIST:END -->

## IA Respons√°vel

A Microsoft est√° comprometida em ajudar nossos clientes a usar nossos produtos de IA de forma respons√°vel, compartilhando nossos aprendizados e construindo parcerias baseadas em confian√ßa por meio de ferramentas como Notas de Transpar√™ncia e Avalia√ß√µes de Impacto. Muitos desses recursos podem ser encontrados em https://aka.ms/RAI. A abordagem da Microsoft para IA respons√°vel √© baseada em nossos princ√≠pios de IA de justi√ßa, confiabilidade e seguran√ßa, privacidade e seguran√ßa, inclus√£o, transpar√™ncia e responsabilidade.

Modelos de linguagem natural, imagem e fala em larga escala - como os usados neste exemplo - podem potencialmente se comportar de maneiras injustas, n√£o confi√°veis ou ofensivas, causando danos. Consulte a [nota de transpar√™ncia do servi√ßo Azure OpenAI](https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text) para se informar sobre riscos e limita√ß√µes.

A abordagem recomendada para mitigar esses riscos √© incluir um sistema de seguran√ßa em sua arquitetura que possa detectar e prevenir comportamentos prejudiciais. O [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) fornece uma camada independente de prote√ß√£o, capaz de detectar conte√∫do prejudicial gerado por usu√°rios e IA em aplicativos e servi√ßos. O Azure AI Content Safety inclui APIs de texto e imagem que permitem detectar material prejudicial. Tamb√©m temos um Content Safety Studio interativo que permite visualizar, explorar e testar c√≥digos de exemplo para detectar conte√∫do prejudicial em diferentes modalidades. A seguinte [documenta√ß√£o de in√≠cio r√°pido](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) orienta voc√™ a fazer solicita√ß√µes ao servi√ßo.

Outro aspecto a ser considerado √© o desempenho geral do aplicativo. Com aplicativos multimodais e multimodelos, consideramos desempenho como o sistema funcionando conforme voc√™ e seus usu√°rios esperam, incluindo n√£o gerar sa√≠das prejudiciais. √â importante avaliar o desempenho do seu aplicativo geral usando [avaliadores de Desempenho e Qualidade e de Risco e Seguran√ßa.](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-metrics-built-in?tabs=warning) Voc√™ tamb√©m tem a capacidade de criar e avaliar com [avaliadores personalizados.](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators)

Voc√™ pode avaliar seu aplicativo de IA em seu ambiente de desenvolvimento usando o [SDK de Avalia√ß√£o do Azure AI.](https://microsoft.github.io/promptflow/index.html) Dado um conjunto de dados de teste ou um alvo, as gera√ß√µes do seu aplicativo de IA generativa s√£o medidas quantitativamente com avaliadores integrados ou avaliadores personalizados de sua escolha. Para come√ßar a usar o SDK de fluxo de prompt para avaliar seu sistema, voc√™ pode seguir o [guia de in√≠cio r√°pido.](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk) Depois de executar uma execu√ß√£o de avalia√ß√£o, voc√™ pode [visualizar os resultados no Azure AI Studio.](https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results)

## Avisos Legais
 
A Microsoft e quaisquer colaboradores concedem a voc√™ uma licen√ßa para a documenta√ß√£o da Microsoft e outros conte√∫dos neste reposit√≥rio sob a [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),
veja [LICENSE](LICENSE) e concedem a voc√™ uma licen√ßa para qualquer c√≥digo no reposit√≥rio sob a  [MIT License](https://opensource.org/licenses/MIT), consulte
[LICENSE-CODE](LICENSE-CODE)
 
Microsoft, Windows, Microsoft Azure e/ou outros produtos e servi√ßos da Microsoft referenciados na documenta√ß√£o podem ser marcas registradas ou marcas registradas da Microsoft nos Estados Unidos e/ou em outros pa√≠ses. As licen√ßas para este projeto n√£o concedem a voc√™ direitos de uso de quaisquer nomes, logotipos ou marcas registradas da Microsoft. As diretrizes gerais de marcas registradas da Microsoft podem ser encontradas em http://go.microsoft.com/fwlink/?LinkID=254653.
 
As informa√ß√µes de privacidade podem ser encontradas em https://privacy.microsoft.com/en-us/
 
A Microsoft e quaisquer colaboradores reservam todos os outros direitos, sejam sob seus respectivos direitos autorais, patentes, ou marcas registradas, seja por implica√ß√£o, estoppel ou de outra forma.

